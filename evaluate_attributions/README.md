# Evaluating Attributions

## Introduction to evaluating model attributions (GridPG - Grid Pointing Game)

We now compute and evaluate the attributions for pre-trained and probed models. To do this follow the next steps in order:

For steps `1-3` you need to `cd /how-to-probe/evaluate_attributions/gridpg`.

### 1. Create a subset of confidently classified images by the model

We set the default confidence to `0.95` feel free to modify it based on your needs and use-case.

```
Do the following in the file get_confident_images.py
1. set path to your model (my_model)
2. set data_file, and data_root
3. set confident_images_dir

Run:
python get_confident_images.py
```

### 2. Create the GridPG images

Now using the subset of correctly and confidently classfied images by `my_model` we create the `2x2` and `3x3` GridPG images.

```
Do the following in file create_point_grid_dataset.py
1. Set base_dir='/path/to/confident_images_dir' 
2. mkdir grid_pg_images_2x2 grid_pg_images_3x3

Run:
python create_point_grid_dataset.py

ls grid_pg_images_2x2 > grid_pg_images_2x2_list.txt
ls grid_pg_images_3x3 > grid_pg_images_3x3_list.txt
```

### 3. Evaluate GridPG, Compactness, and Complexity Scores

Once we have completed steps 1 and 2, we will now evaluate the GridPG score, Complexity (Shannon's Entropy) and Compactness (Gini Index) for the heatmaps generated by different attribution methods for the given `my_model`.

```
Do the following in file eval_gridpg_compactness_complexity.py
1. set path to your model (my_model)
2. set path to data_file='/path/to/grid_pg_images_3x3_list.txt' and data_root='/path/to/grid_pg_images_3x3'
3. set path to output_dir = '/path/to/output_dir'

Run:
python eval_gridpg_compactness_complexity.py

```

The above script will supports the following XAI attribution methods for model classifcation: `Layerwise Relevance Propagation (LRP), GradCAM, IntegratedGradients, InputXGradient, GuidedBackpropagation, and B-cos`.

**Note**: By default the above script is configured to work with `3x3` input grids, however you can modify the script by updating the respective `data_file`, `data_root` and `map_size=2` in `eval_gridpg_compactness_complexity.py`.

#### Additionally we also compute Perturbation Based Attribution methods, specifically LIME

Similar to step 3. above:
```
Do the following in file eval_gridpg_lime.py
1. set path to your model (my_model)
2. set path to data_file='/path/to/grid_pg_images_3x3_list.txt' and data_root='/path/to/grid_pg_images_3x3'
3. set path to output_dir = '/path/to/output_dir'

Run:
python eval_gridpg_lime.py
```

## EPG (Energy Pointing Game) on VOC and COCO

Similar to GridPG, EPG is also a localisation metric to evaluate the class-specificity and quality of heatmap-based explanation methods. We support `LRP, GradCAM, IntergratedGradients, InputXGradient, GuidedBackpropagation, and B-cos`.

For below `cd /how-to-probe/evaluate_attributions/epg`

### For VOC

Similar to step 3. above:
```
Do the following in file eval_voc_epg.py
1. set path to your model (my_model)
2. set path to data_root='/path/to/VOCdevkit'
3. set path to output_dir = '/path/to/output_dir'

Run:
python eval_voc_epg.py
```

### For COCO
```
Do the following in file eval_voc_epg.py
1. set path to your model (my_model)
2. set path to data_root='/path/to/COCO2014/' 
3. set path to annotations_file='/path/to/coco/annotations/instances_val2014.json'
4. set path to output_dir = '/path/to/output_dir'

Run:
python eval_coco_epg.py
```

`Note, the LIME evaluations for EPG are not present at the moment, however looking at the above files and the lime evaluation for GridPG it should be easy to extend similarly.`
